{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Using MLJ to classifiy the MNIST image dataset"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "const DIR = @__DIR__\n",
    "Pkg.activate(DIR)\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Julia version** is assumed to be 1.6.*"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using Flux\n",
    "import MLJFlux\n",
    "using Random\n",
    "Random.seed!(123)\n",
    "\n",
    "MLJ.color_off()\n",
    "\n",
    "using Plots\n",
    "pyplot(size=(600, 300*(sqrt(5)-1)));"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Basic training"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Downloading the MNIST image dataset:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import Flux.Data.MNIST\n",
    "images, labels = MNIST.images(), MNIST.labels();"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "In MLJ, integers cannot be used for encoding categorical data, so we\n",
    "must force the labels to have the `Multiclass` [scientific\n",
    "type](https://alan-turing-institute.github.io/MLJScientificTypes.jl/dev/). For\n",
    "more on this, see [Working with Categorical\n",
    "Data](https://alan-turing-institute.github.io/MLJ.jl/dev/working_with_categorical_data/)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "labels = coerce(labels, Multiclass);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Checking scientific types:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "@assert scitype(images) <: AbstractVector{<:Image}\n",
    "@assert scitype(labels) <: AbstractVector{<:Finite}"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Looks good."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For general instructions on coercing image data, see [Type coercion\n",
    "for image\n",
    "data](https://alan-turing-institute.github.io/MLJScientificTypes.jl/dev/#Type-coercion-for-image-data-1)"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "images[1]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We start by defining a suitable `Builder` object. This is a recipe\n",
    "for building the neural network. Our builder will work for images of\n",
    "any (constant) size, whether they be color or black and white (ie,\n",
    "single or multi-channel).  The architecture always consists of six\n",
    "alternating convolution and max-pool layers, and a final dense\n",
    "layer; the filter size and the number of channels after each\n",
    "convolution layer is customisable."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "import MLJFlux\n",
    "struct MyConvBuilder\n",
    "    filter_size::Int\n",
    "    channels1::Int\n",
    "    channels2::Int\n",
    "    channels3::Int\n",
    "end\n",
    "\n",
    "flatten(x::AbstractArray) = reshape(x, :, size(x)[end])\n",
    "half(x) = div(x, 2)\n",
    "\n",
    "function MLJFlux.build(b::MyConvBuilder, n_in, n_out, n_channels)\n",
    "\n",
    "    k, c1, c2, c3 = b.filter_size, b.channels1, b.channels2, b.channels3\n",
    "\n",
    "    mod(k, 2) == 1 || error(\"`filter_size` must be odd. \")\n",
    "\n",
    "    p = div(k - 1, 2) # padding to preserve image size on convolution:\n",
    "\n",
    "    h = n_in[1] |> half |> half |> half # final \"image\" height\n",
    "    w = n_in[2] |> half |> half |> half # final \"image\" width\n",
    "\n",
    "    return Chain(\n",
    "        Conv((k, k), n_channels => c1, pad=(p, p), relu),\n",
    "        MaxPool((2, 2)),\n",
    "        Conv((k, k), c1 => c2, pad=(p, p), relu),\n",
    "        MaxPool((2, 2)),\n",
    "        Conv((k, k), c2 => c3, pad=(p, p), relu),\n",
    "        MaxPool((2 ,2)),\n",
    "        flatten,\n",
    "        Dense(h*w*c3, n_out))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Note.** There is no final `softmax` here, as this is applied by\n",
    "default in all MLJFLux classifiers. Customisation of this behaviour\n",
    "is controlled using using the `finaliser` hyperparameter of the\n",
    "classifier."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We now define the MLJ model. If you have a GPU, substitute\n",
    "`acceleration=CUDALibs()` below:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "ImageClassifier = @load ImageClassifier\n",
    "clf = ImageClassifier(builder=MyConvBuilder(3, 16, 32, 32),\n",
    "                      acceleration=CPU1(),\n",
    "                      batch_size=50,\n",
    "                      epochs=10)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can add Flux options `optimiser=...` and `loss=...` here. At\n",
    "present, `loss` must be a Flux-compatible loss, not an MLJ measure."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Binding the model with data in an MLJ machine:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(clf, images, labels);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training for 10 epochs on the first 500 images:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(mach, rows=1:500, verbosity=2);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspecting:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "report(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "chain = fitted_params(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Flux.params(chain)[2]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding 20 more epochs:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "clf.epochs = clf.epochs + 20\n",
    "fit!(mach, rows=1:500);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computing an out-of-sample estimate of the loss:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "predicted_labels = predict(mach, rows=501:1000);\n",
    "cross_entropy(predicted_labels, labels[501:1000]) |> mean"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Or, in one line (after resetting the RNG seed to ensure the same\n",
    "result):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "Random.seed!(123)\n",
    "evaluate!(mach,\n",
    "          resampling=Holdout(fraction_train=0.5),\n",
    "          measure=cross_entropy,\n",
    "          rows=1:1000,\n",
    "          verbosity=0)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping the MLJFlux model with iteration controls"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Any iterative MLJ model implementing the warm restart functionality\n",
    "illustrated above for `ImageClassifier` can be wrapped in *iteration\n",
    "controls*, as we demonstrate next. For more on MLJ's\n",
    "`IteratedModel` wrapper, see the [MLJ\n",
    "documentation](https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/)."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The \"self-iterating\" model, called `imodel` below, is for iterating the\n",
    "image classifier defined above until one of the following stopping\n",
    "criterion apply:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `Patience(3)` (3 consecutive increases in the loss)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `InvalidValue()` (an out-of-sample loss, or a training loss,\n",
    "  is `NaN`, `Inf`, or `-Inf`)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- `TimeLimit(t=1/60)` (training time has exceeded one minute)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Additionally, training a machine bound to `imodel` will:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- save a snapshot of the machine every three epochs"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- record the out-of-sample loss and training losses for plotting"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For a complete list of controls, see [this\n",
    "table](https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/#Controls-provided)."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "losses = []\n",
    "training_losses = [];\n",
    "\n",
    "add_loss(loss) = push!(losses, loss)\n",
    "add_training_loss(losses) = push!(training_losses, losses[end])\n",
    "\n",
    "imodel = IteratedModel(model=clf,\n",
    "                       controls=[Step(1),      # train one epoch at a time\n",
    "                                 Patience(2),\n",
    "                                 InvalidValue(),\n",
    "                                 TimeLimit(0.5),\n",
    "                                 Save(joinpath(DIR, \"mnist_machine.jlso\")),\n",
    "                                 WithLossDo(), # for logging to `Info`\n",
    "                                 WithLossDo(add_loss),\n",
    "                                 WithTrainingLossesDo(add_training_loss)],\n",
    "                       resampling=Holdout(fraction_train=0.7),\n",
    "                       measure=log_loss,\n",
    "                       retrain=false)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Binding our self-iterating model to data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(imodel, images, labels)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And training on the first 500 images:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "fit!(mach, rows=1:500)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "A comparison of the training and out-of-sample losses:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(losses,\n",
    "     title=\"Cross Entropy\",\n",
    "     xlab = \"epoch\",\n",
    "     label=\"out-of-sample\")\n",
    "plot!(training_losses, label=\"training\")"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Retrieving a snapshot for a prediction:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach2 = machine(joinpath(DIR, \"mnist_machine5.jlso\"))\n",
    "predict_mode(mach2, images[501:503])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.0",
   "language": "julia"
  }
 },
 "nbformat": 4
}
