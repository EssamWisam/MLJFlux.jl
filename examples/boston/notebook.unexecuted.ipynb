{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Building an MLJFlux regression model for the Boston house\n",
    "# price dataset"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Pkg\n",
    "Pkg.activate(@__DIR__)\n",
    "Pkg.instantiate()"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Julia version** is assumed to be 1.6.*"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using MLJ\n",
    "using MLJFlux\n",
    "using Flux\n",
    "using Plots"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This tutorial uses MLJ's `IteratedModel` wrapper to transform the\n",
    "MLJFlux `NeuralNetworkRegressor` into a model that **automatically\n",
    "selects the number of epochs** required to optimize an out-of-sample\n",
    "loss."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We also show how to include the model in a **pipeline** to carry out\n",
    "standardization of the features and target."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loading data"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "data = OpenML.load(531); # Loads from https://www.openml.org/d/531"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The target `y` is `:MEDV` and everything else except `:CHAS` goes\n",
    "into the features `X`:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "y, X = unpack(data, ==(:MEDV), !=(:CHAS); rng=123);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We specified the seed `rng` to shuffle the observations. The Charles\n",
    "River dummy variable `:CHAS` is dropped, as not deemed to be\n",
    "relevant."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspecting the scientific types:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "scitype(y)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "schema(X)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll regard `:RAD` (index of accessibility to radial highways) as\n",
    "`Continuous` as MLJFlux models don't handle ordered factors:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "X = coerce(X, :RAD => Continuous);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's split off a test set for final testing:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "(X, Xtest), (y, ytest) = partition((X, y), 0.7, multi=true);"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining a builder"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In the macro call below, `n_in` is expected to represent the number\n",
    "of inputs features and `rng` a RNG (builders are generic, ie can be\n",
    "applied to data with any number of input features):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "builder = MLJFlux.@builder begin\n",
    "    init=Flux.glorot_uniform(rng)\n",
    "    Chain(Dense(n_in, 64, relu, init=init),\n",
    "          Dense(64, 32, relu, init=init),\n",
    "          Dense(32, 1, init=init))\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defining a MLJFlux model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "NeuralNetworkRegressor = @load NeuralNetworkRegressor\n",
    "    model = NeuralNetworkRegressor(builder=builder,\n",
    "                                   rng=123,\n",
    "                                   epochs=20)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Standardization"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "The following wraps our regressor in feature and target standardizations:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe = Standardizer |> TransformedTargetModel(model, target=Standardizer)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that our original neural network model is now a\n",
    "hyper-parameter of the composite `pipe`, with the automatically\n",
    "generated name, `:neural_network_regressor`."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Choosing a learning rate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's see how the training losses look for the default optimiser. For\n",
    "MLJFlux models, `fit!` will print these losses if we bump the\n",
    "verbosity level (default is always 1):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "mach = machine(pipe, X, y)\n",
    "fit!(mach, verbosity=2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "They are also extractable from the training report (which includes\n",
    "the pre-train loss):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "report(mach).transformed_target_model_deterministic.model.training_losses"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next, let's visually compare a few learning rates:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plt = plot()\n",
    "rates = [5e-5, 1e-4, 0.005, 0.001, 0.05]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "By default, changing only the optimiser will not trigger a\n",
    "cold-restart when we `fit!` (to allow for adaptive learning rate\n",
    "control). So we call `fit!` with the `force=true`\n",
    "option. (Alternatively, one can change the hyper-parameter\n",
    "`pipe.neural_network_regressor.optimiser_changes_trigger_retraining`\n",
    "to `true`.)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll skip the first few losses to get a better vertical scale in\n",
    "our plot."
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "foreach(rates) do η\n",
    "    pipe.transformed_target_model_deterministic.model.optimiser.eta = η\n",
    "    fit!(mach, force=true, verbosity=0)\n",
    "    losses =\n",
    "        report(mach).transformed_target_model_deterministic.model.training_losses[3:end]\n",
    "    plot!(1:length(losses), losses, label=η)\n",
    "end\n",
    "plt"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "savefig(joinpath(\"assets\", \"learning_rate.png\"))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll go with the second most conservative rate for now:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "pipe.transformed_target_model_deterministic.model.optimiser.eta = 0.0001"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Wrapping in iteration control"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "We want a model that trains until an out-of-sample loss satisfies\n",
    "the `NumberSinceBest(6)` stopping criterion. We'll add some fallback\n",
    "stopping criterion `InvalidValue` and `TimeLimit(1/60)`, and\n",
    "controls to print traces of the losses."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "For initializing or clearing the traces:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "clear() = begin\n",
    "    global losses = []\n",
    "    global training_losses = []\n",
    "    global epochs = []\n",
    "    return nothing\n",
    "end"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And to update the traces:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "update_loss(loss) = push!(losses, loss)\n",
    "update_training_loss(report) =\n",
    "    push!(training_losses,\n",
    "          report.transformed_target_model_deterministic.model.training_losses[end])\n",
    "update_epochs(epoch) = push!(epochs, epoch)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The controls to apply (see\n",
    "[here](https://alan-turing-institute.github.io/MLJ.jl/dev/controlling_iterative_models/#Controls-provided)\n",
    "for the complete list):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "controls=[Step(1),\n",
    "          NumberSinceBest(6),\n",
    "          InvalidValue(),\n",
    "          TimeLimit(1/60),\n",
    "          WithLossDo(update_loss),\n",
    "          WithReportDo(update_training_loss),\n",
    "          WithIterationsDo(update_epochs)]"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we create a \"self-iterating\" version of the pipeline. Note\n",
    "that the iteration parameter is a nested hyperparameter:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "iterated_pipe =\n",
    "    IteratedModel(model=pipe,\n",
    "                  controls=controls,\n",
    "                  resampling=Holdout(fraction_train=0.8),\n",
    "                  measure = l2)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training the wrapped model on all the train/validation data:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "clear()\n",
    "mach = machine(iterated_pipe, X, y)\n",
    "fit!(mach)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "And plotting the traces:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "plot(epochs, losses,\n",
    "     xlab = \"epoch\",\n",
    "     ylab = \"mean sum of squares error\",\n",
    "     label=\"out-of-sample\",\n",
    "     legend = :topleft);\n",
    "scatter!(twinx(), epochs, training_losses, label=\"training\", color=:red)"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "savefig(joinpath(\"assets\", \"loss.png\"))"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "**How `IteratedModel` works.** Training an `IteratedModel` means\n",
    "holding out some data (80% in this case) so an out-of-sample loss\n",
    "can be tracked and used in the specified stopping criterion,\n",
    "`NumberSinceBest(4)`. However, once the stop is triggered, the model\n",
    "wrapped by `IteratedModel` (our pipeline model) is retrained on all\n",
    "data for the same number of iterations. Calling `predict(mach,\n",
    "Xnew)` on new data uses the updated learned parameters."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "In other words, `iterated_model` is a \"self-iterating\" version of\n",
    "the original model, where `epochs` has been transformed from\n",
    "hyper-parameter to *learned* parameter."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## An evaluation of the self-iterating model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here's an estimate of performance of our \"self-iterating\"\n",
    "model:"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "e = evaluate!(mach,\n",
    "              resampling=CV(nfolds=8),\n",
    "              measures=[l1, l2])"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "using Measurements\n",
    "l1_loss = e.measurement[1] ± std(e.per_fold[1])/sqrt(7)\n",
    "@show l1_loss"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We take this estimate of the uncertainty of the generalization error with a [grain of salt](https://direct.mit.edu/neco/article-abstract/10/7/1895/6224/Approximate-Statistical-Tests-for-Comparing))."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Comparison with other models on the test set"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Although we cannot assign them statistical significance, here are\n",
    "comparisons, on the untouched test set, of the eror of our\n",
    "self-iterating neural network regressor with a couple of other\n",
    "models trained on the same data (using default hyperparameters):"
   ],
   "metadata": {}
  },
  {
   "outputs": [],
   "cell_type": "code",
   "source": [
    "function performance(model)\n",
    "    mach = machine(model, X, y) |> fit!\n",
    "    yhat = predict(mach, Xtest)\n",
    "    l1(yhat, ytest) |> mean\n",
    "end\n",
    "performance(iterated_pipe)\n",
    "\n",
    "three_models = [(@load EvoTreeRegressor)(), # tree boosting model\n",
    "                (@load LinearRegressor pkg=MLJLinearModels)(),\n",
    "                iterated_pipe]\n",
    "\n",
    "errs = performance.(three_models)\n",
    "\n",
    "(models=MLJ.name.(three_models), mean_square_errors=errs) |> pretty"
   ],
   "metadata": {},
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "*This notebook was generated using [Literate.jl](https://github.com/fredrikekre/Literate.jl).*"
   ],
   "metadata": {}
  }
 ],
 "nbformat_minor": 3,
 "metadata": {
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  },
  "kernelspec": {
   "name": "julia-1.6",
   "display_name": "Julia 1.6.5",
   "language": "julia"
  }
 },
 "nbformat": 4
}
